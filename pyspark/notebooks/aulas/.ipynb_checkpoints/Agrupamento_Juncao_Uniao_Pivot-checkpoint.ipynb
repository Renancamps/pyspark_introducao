{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd47d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, FloatType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3ec350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/19 23:28:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/19 23:28:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/01/19 23:28:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Iniciando com Spark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddf012",
   "metadata": {},
   "source": [
    "### Lendo Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21413525",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_countries = '../../datalake/transient/departments/countries'\n",
    "df_countries = spark.read.format('csv')\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"sep\", \",\")\\\n",
    ".option(\"quote\",\"\\'\")\\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(path_countries)\n",
    "#transient\\csv\\olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827562bc-12da-4d86-8ca6-e569c57b8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_regions = '../../datalake/transient/departments/regions'\n",
    "df_regions = spark.read.format('csv')\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"sep\", \",\")\\\n",
    ".option(\"quote\",\"\\'\")\\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(path_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b044f3-8421-4648-bcda-f216f1330d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jobs = '../../datalake/transient/departments/jobs'\n",
    "df_jobs = spark.read.format('csv')\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"sep\", \",\")\\\n",
    ".option(\"quote\",\"\\'\")\\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(path_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524de348-6108-434a-a838-537e86389e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_employees = '../../datalake/transient/departments/employees'\n",
    "df_employees = spark.read.format('csv')\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"sep\", \",\")\\\n",
    ".option(\"quote\",\"\\'\")\\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(path_employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a400f9-59f1-4f3f-8371-f2a69adb8ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23defc96-1e02-45d7-8c83-ef7cf57a0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+\n",
      "|country_id|country_name|region_id|\n",
      "+----------+------------+---------+\n",
      "|        AR|   Argentina|        2|\n",
      "|        AU|   Australia|        3|\n",
      "+----------+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_countries.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b3f088-8829-41ef-8dd7-c0f8b4b41ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|region_id|         region_name|\n",
      "+---------+--------------------+\n",
      "|        1|              Europe|\n",
      "|        2|            Americas|\n",
      "|        3|                Asia|\n",
      "|        4|Middle East and A...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_regions.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47294ea-9e68-4680-af60-0f8a3f63988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(97,\"Terra Média\"),(98,\"Westeros\"),(98,\"Esteros\"),(100,\"Sistema Solar\")]\n",
    "\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"region_id\",IntegerType(),True), \\\n",
    "    StructField(\"region_name\",StringType(),True)\n",
    "  ])\n",
    "\n",
    "df_region2 = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19768d00-ee4a-4a86-8984-83e8d5cf879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(50,\"Valfenda\",91),(51,\"Kings Landing\",98),(51,\"Terra\",101)]\n",
    "\n",
    "#country_id|country_name|region_id\n",
    "schema = StructType([ \\\n",
    "    StructField(\"country_id\",IntegerType(),True), \\\n",
    "    StructField(\"country_name\",StringType(),True), \\\n",
    "    StructField(\"region_id\",IntegerType(),True),\n",
    "  ])\n",
    "\n",
    "df_countries2 = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf45a34-aee6-4628-8a72-1e2a520a9d4d",
   "metadata": {},
   "source": [
    "### **Union** ###\n",
    "Podemos unir dataframes que tenham o mesmo schema, o efeito seria o mesmo de empilhar os dataframes <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e8f4a9-51de-4e2a-aad3-33fc7de8ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions3 = df_regions.union(df_region2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed901e71-763f-4978-92a4-0124c0499e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|region_id|         region_name|\n",
      "+---------+--------------------+\n",
      "|        1|              Europe|\n",
      "|        2|            Americas|\n",
      "|        3|                Asia|\n",
      "|        4|Middle East and A...|\n",
      "|       97|         Terra Média|\n",
      "|       98|            Westeros|\n",
      "|       98|             Esteros|\n",
      "|      100|       Sistema Solar|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_regions3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a23c50f-5b8d-4bbd-9dc0-cb1a68efbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries3 = df_countries.union(df_countries2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3710e057-3087-4bf5-bf62-0987e16dbeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+\n",
      "|country_id|        country_name|region_id|\n",
      "+----------+--------------------+---------+\n",
      "|        AR|           Argentina|        2|\n",
      "|        AU|           Australia|        3|\n",
      "|        BE|             Belgium|        1|\n",
      "|        BR|              Brazil|        2|\n",
      "|        CA|              Canada|        2|\n",
      "|        CH|         Switzerland|        1|\n",
      "|        CN|               China|        3|\n",
      "|        DE|             Germany|        1|\n",
      "|        DK|             Denmark|        1|\n",
      "|        EG|               Egypt|        4|\n",
      "|        FR|              France|        1|\n",
      "|        HK|            HongKong|        3|\n",
      "|        IL|              Israel|        4|\n",
      "|        IN|               India|        3|\n",
      "|        IT|               Italy|        1|\n",
      "|        JP|               Japan|        3|\n",
      "|        KW|              Kuwait|        4|\n",
      "|        MX|              Mexico|        2|\n",
      "|        NG|             Nigeria|        4|\n",
      "|        NL|         Netherlands|        1|\n",
      "|        SG|           Singapore|        3|\n",
      "|        UK|      United Kingdom|        1|\n",
      "|        US|United States of ...|        2|\n",
      "|        ZM|              Zambia|        4|\n",
      "|        ZW|            Zimbabwe|        4|\n",
      "|        50|            Valfenda|       91|\n",
      "|        51|       Kings Landing|       98|\n",
      "|        51|               Terra|      101|\n",
      "+----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_countries3.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615a07a-2d21-4ae2-afac-084a2d008220",
   "metadata": {},
   "source": [
    "### **Join** ###\n",
    "Outra possibilidade muito utilizada é a **junção** ou **join** entre dataframes, a junção necessita que os dataframes envolvidos tenham um campo em comum, semelhante a relação de chaves primarias e estrageiras do SQL tradicional<br>\n",
    "**Tipos de junções**;<br>\n",
    "• inner - Junção padrão, só realiza a junção se a mesma chave exista em todos os dataframes envolvidos ;<br>\n",
    "• left - Sempre retorna os elementos do dataframe da esquerda, os caso os elementos do dataframe da esquerda não sejam encontrados, as colunas desse dataframe ;<br>\n",
    "• full - ;<br>\n",
    "• anti - ;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d731f-2bd6-4316-83ae-dc7955652710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06facfb8-4677-42b5-ab5a-bdace7124c6b",
   "metadata": {},
   "source": [
    "### **Inner Join** ###\n",
    "Outra possibilidade muito utilizada é a **junção** ou **join** entre dataframes, a junção necessita que os dataframes envolvidos tenham um campo em comum, semelhante a relação de chaves primarias e estrageiras do SQL tradicional<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc0276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_regions3.region_id == df_countries3.region_id\n",
    "df_join = df_regions3.join(df_countries3, condicao ,'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e2c769-5601-4634-b6e4-05b9abd75626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=========================>                                (4 + 5) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|region_id|         region_name|country_id|        country_name|region_id|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|        1|              Europe|        BE|             Belgium|        1|\n",
      "|        1|              Europe|        CH|         Switzerland|        1|\n",
      "|        1|              Europe|        DE|             Germany|        1|\n",
      "|        1|              Europe|        DK|             Denmark|        1|\n",
      "|        1|              Europe|        FR|              France|        1|\n",
      "|        1|              Europe|        IT|               Italy|        1|\n",
      "|        1|              Europe|        NL|         Netherlands|        1|\n",
      "|        1|              Europe|        UK|      United Kingdom|        1|\n",
      "|        2|            Americas|        AR|           Argentina|        2|\n",
      "|        2|            Americas|        BR|              Brazil|        2|\n",
      "|        2|            Americas|        CA|              Canada|        2|\n",
      "|        2|            Americas|        MX|              Mexico|        2|\n",
      "|        2|            Americas|        US|United States of ...|        2|\n",
      "|        3|                Asia|        AU|           Australia|        3|\n",
      "|        3|                Asia|        CN|               China|        3|\n",
      "|        3|                Asia|        HK|            HongKong|        3|\n",
      "|        3|                Asia|        IN|               India|        3|\n",
      "|        3|                Asia|        JP|               Japan|        3|\n",
      "|        3|                Asia|        SG|           Singapore|        3|\n",
      "|        4|Middle East and A...|        EG|               Egypt|        4|\n",
      "|        4|Middle East and A...|        IL|              Israel|        4|\n",
      "|        4|Middle East and A...|        KW|              Kuwait|        4|\n",
      "|        4|Middle East and A...|        NG|             Nigeria|        4|\n",
      "|        4|Middle East and A...|        ZM|              Zambia|        4|\n",
      "|        4|Middle East and A...|        ZW|            Zimbabwe|        4|\n",
      "|       98|            Westeros|        51|       Kings Landing|       98|\n",
      "|       98|             Esteros|        51|       Kings Landing|       98|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743d34d-15c2-4b28-aaa1-b5dd114a274f",
   "metadata": {},
   "source": [
    "### **Left Join** ###\n",
    "Sempre retorna os elementos do dataframe da esquerda, os caso os elementos do dataframe da direita não sejam encontrados, as colunas desse dataframe aparecem como nulas;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41f07553-d9b8-42b8-980e-95673f8c96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_regions3.region_id == df_countries3.region_id\n",
    "df_join = df_regions3.join(df_countries3, condicao ,'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "899d1bfa-b20d-4dab-bd5e-de5132b92c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|region_id|         region_name|country_id|        country_name|region_id|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|        1|              Europe|        UK|      United Kingdom|        1|\n",
      "|        1|              Europe|        NL|         Netherlands|        1|\n",
      "|        1|              Europe|        IT|               Italy|        1|\n",
      "|        1|              Europe|        FR|              France|        1|\n",
      "|        1|              Europe|        DK|             Denmark|        1|\n",
      "|        1|              Europe|        DE|             Germany|        1|\n",
      "|        1|              Europe|        CH|         Switzerland|        1|\n",
      "|        1|              Europe|        BE|             Belgium|        1|\n",
      "|        3|                Asia|        SG|           Singapore|        3|\n",
      "|        3|                Asia|        JP|               Japan|        3|\n",
      "|        3|                Asia|        IN|               India|        3|\n",
      "|        3|                Asia|        HK|            HongKong|        3|\n",
      "|        3|                Asia|        CN|               China|        3|\n",
      "|        3|                Asia|        AU|           Australia|        3|\n",
      "|        4|Middle East and A...|        ZW|            Zimbabwe|        4|\n",
      "|        4|Middle East and A...|        ZM|              Zambia|        4|\n",
      "|        4|Middle East and A...|        NG|             Nigeria|        4|\n",
      "|        4|Middle East and A...|        KW|              Kuwait|        4|\n",
      "|        4|Middle East and A...|        IL|              Israel|        4|\n",
      "|        4|Middle East and A...|        EG|               Egypt|        4|\n",
      "|        2|            Americas|        US|United States of ...|        2|\n",
      "|        2|            Americas|        MX|              Mexico|        2|\n",
      "|        2|            Americas|        CA|              Canada|        2|\n",
      "|        2|            Americas|        BR|              Brazil|        2|\n",
      "|        2|            Americas|        AR|           Argentina|        2|\n",
      "|       97|         Terra Média|      null|                null|     null|\n",
      "|       98|            Westeros|        51|       Kings Landing|       98|\n",
      "|       98|             Esteros|        51|       Kings Landing|       98|\n",
      "|      100|       Sistema Solar|      null|                null|     null|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e024d-9c85-4176-be04-ed9abeb4f920",
   "metadata": {},
   "source": [
    "### **Full Join** ###\n",
    "Sempre retorna os elementos do dataframe da esquerda, os caso os elementos do dataframe da direita não sejam encontrados, as colunas desse dataframe aparecem como nulas;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50612352-3bd2-4d50-a128-d13a86489acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_regions3.region_id == df_countries3.region_id\n",
    "df_join = df_regions3.join(df_countries3, condicao ,'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247c4a0c-8db2-4333-b52f-e07eddcd9c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|region_id|         region_name|country_id|        country_name|region_id|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|        1|              Europe|        BE|             Belgium|        1|\n",
      "|        1|              Europe|        CH|         Switzerland|        1|\n",
      "|        1|              Europe|        DE|             Germany|        1|\n",
      "|        1|              Europe|        DK|             Denmark|        1|\n",
      "|        1|              Europe|        FR|              France|        1|\n",
      "|        1|              Europe|        IT|               Italy|        1|\n",
      "|        1|              Europe|        NL|         Netherlands|        1|\n",
      "|        1|              Europe|        UK|      United Kingdom|        1|\n",
      "|        2|            Americas|        AR|           Argentina|        2|\n",
      "|        2|            Americas|        BR|              Brazil|        2|\n",
      "|        2|            Americas|        CA|              Canada|        2|\n",
      "|        2|            Americas|        MX|              Mexico|        2|\n",
      "|        2|            Americas|        US|United States of ...|        2|\n",
      "|        3|                Asia|        AU|           Australia|        3|\n",
      "|        3|                Asia|        CN|               China|        3|\n",
      "|        3|                Asia|        HK|            HongKong|        3|\n",
      "|        3|                Asia|        IN|               India|        3|\n",
      "|        3|                Asia|        JP|               Japan|        3|\n",
      "|        3|                Asia|        SG|           Singapore|        3|\n",
      "|        4|Middle East and A...|        EG|               Egypt|        4|\n",
      "|        4|Middle East and A...|        IL|              Israel|        4|\n",
      "|        4|Middle East and A...|        KW|              Kuwait|        4|\n",
      "|        4|Middle East and A...|        NG|             Nigeria|        4|\n",
      "|        4|Middle East and A...|        ZM|              Zambia|        4|\n",
      "|        4|Middle East and A...|        ZW|            Zimbabwe|        4|\n",
      "|     null|                null|        50|            Valfenda|       91|\n",
      "|       97|         Terra Média|      null|                null|     null|\n",
      "|       98|            Westeros|        51|       Kings Landing|       98|\n",
      "|       98|             Esteros|        51|       Kings Landing|       98|\n",
      "|      100|       Sistema Solar|      null|                null|     null|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce02e8-5e9a-4c2e-9a99-c5d6ee9cec2c",
   "metadata": {},
   "source": [
    "### **Anti Join** ###\n",
    "Sempre retorna os elementos do dataframe da direita, quem não sejam encontrados no dataframe da esquerda;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2697083-799c-4a6f-b742-f6b155686725",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_regions3.region_id == df_countries.region_id\n",
    "df_join = df_regions3.join(df_countries, condicao ,'anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aacc40e-af4a-4f12-9561-91c334257dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|region_id|  region_name|\n",
      "+---------+-------------+\n",
      "|       97|  Terra Média|\n",
      "|       98|     Westeros|\n",
      "|       98|      Esteros|\n",
      "|      100|Sistema Solar|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8229fbeb-d7d1-489d-b2d5-94cf12421d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c76a0bae-89eb-458d-b85b-018318d337ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,\"Profit\",100.0),\n",
    "        (2,\"Profit\",100.0),\n",
    "        (3,\"Profit\",100.0),\n",
    "        (4,\"Profit\",100.0),\n",
    "        (5,\"Profit\",100.0),\n",
    "        (6,\"Profit\",100.0),\n",
    "        (7,\"Profit\",100.0),\n",
    "        (8,\"Profit\",100.0),\n",
    "        (9,\"Profit\",100.0),\n",
    "       (10,\"Profit\",100.0),\n",
    "       (11,\"Profit\",100.0),\n",
    "       (12,\"Profit\",100.0),\n",
    "         (1,\"Revenue\",500.0),\n",
    "        (2,\"Revenue\",500.0),\n",
    "        (3,\"Revenue\",500.0),\n",
    "        (4,\"Revenue\",500.0),\n",
    "        (5,\"Revenue\",555.0),\n",
    "        (6,\"Revenue\",777.0),\n",
    "        (7,\"Revenue\",800.0),\n",
    "        (8,\"Revenue\",900.0),\n",
    "        (9,\"Revenue\",1000.0),\n",
    "       (10,\"Revenue\",300.0),\n",
    "       (12,\"Revenue\",400.0)\n",
    "      ]\n",
    "\n",
    "#country_id|country_name|region_id\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Month\",IntegerType(),True), \\\n",
    "    StructField(\"Indicator\",StringType(),True), \\\n",
    "    StructField(\"Amount\",FloatType(),True),\n",
    "  ])\n",
    "\n",
    "df_profit = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d72952c-c067-4ee1-ac27-25454d8ba25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------+\n",
      "|Month|Indicator|Amount|\n",
      "+-----+---------+------+\n",
      "|    1|   Profit| 100.0|\n",
      "|    2|   Profit| 100.0|\n",
      "|    3|   Profit| 100.0|\n",
      "|    4|   Profit| 100.0|\n",
      "|    5|   Profit| 100.0|\n",
      "|    6|   Profit| 100.0|\n",
      "|    7|   Profit| 100.0|\n",
      "|    8|   Profit| 100.0|\n",
      "|    9|   Profit| 100.0|\n",
      "|   10|   Profit| 100.0|\n",
      "|   11|   Profit| 100.0|\n",
      "|   12|   Profit| 100.0|\n",
      "|    1|  Revenue| 500.0|\n",
      "|    2|  Revenue| 500.0|\n",
      "|    3|  Revenue| 500.0|\n",
      "|    4|  Revenue| 500.0|\n",
      "|    5|  Revenue| 555.0|\n",
      "|    6|  Revenue| 777.0|\n",
      "|    7|  Revenue| 800.0|\n",
      "|    8|  Revenue| 900.0|\n",
      "+-----+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_profit.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2793271-fda4-446f-ac9e-dc0673121583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Indicator: string (nullable = true)\n",
      " |-- 1: double (nullable = true)\n",
      " |-- 2: double (nullable = true)\n",
      " |-- 3: double (nullable = true)\n",
      " |-- 4: double (nullable = true)\n",
      " |-- 5: double (nullable = true)\n",
      " |-- 6: double (nullable = true)\n",
      " |-- 7: double (nullable = true)\n",
      " |-- 8: double (nullable = true)\n",
      " |-- 9: double (nullable = true)\n",
      " |-- 10: double (nullable = true)\n",
      " |-- 11: double (nullable = true)\n",
      " |-- 12: double (nullable = true)\n",
      "\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "|Indicator|1    |2    |3    |4    |5    |6    |7    |8    |9     |10   |11   |12   |\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "|Profit   |100.0|100.0|100.0|100.0|100.0|100.0|100.0|100.0|100.0 |100.0|100.0|100.0|\n",
      "|Revenue  |500.0|500.0|500.0|500.0|555.0|777.0|800.0|900.0|1000.0|300.0|null |400.0|\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pivot = df_profit.groupBy(\"Indicator\").pivot(\"Month\").sum(\"Amount\")\n",
    "df_pivot.printSchema()\n",
    "df_pivot.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54cf74f5-244f-401b-aa6a-3af1cde366fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Indicator: string (nullable = true)\n",
      " |-- 1: double (nullable = true)\n",
      " |-- 2: double (nullable = true)\n",
      " |-- 3: double (nullable = true)\n",
      " |-- 4: double (nullable = true)\n",
      " |-- 5: double (nullable = true)\n",
      " |-- 6: double (nullable = true)\n",
      " |-- 7: double (nullable = true)\n",
      " |-- 8: double (nullable = true)\n",
      " |-- 9: double (nullable = true)\n",
      " |-- 10: double (nullable = true)\n",
      " |-- 11: double (nullable = true)\n",
      " |-- 12: double (nullable = true)\n",
      "\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "|Indicator|1    |2    |3    |4    |5    |6    |7    |8    |9     |10   |11   |12   |\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "|Profit   |100.0|100.0|100.0|100.0|100.0|100.0|100.0|100.0|100.0 |100.0|100.0|100.0|\n",
      "|Revenue  |500.0|500.0|500.0|500.0|555.0|777.0|800.0|900.0|1000.0|300.0|null |400.0|\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "months = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "df_pivot = df_profit.groupBy(\"Indicator\").pivot(\"Month\", months).sum(\"Amount\")\n",
    "df_pivot.printSchema()\n",
    "df_pivot.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "781903e8-46dd-4a0b-a2c9-d992f8c12cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###UnPivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8d5c631-4cb0-4807-bc8f-8328dccbe201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+\n",
      "|Indicator|Month|Amount|\n",
      "+---------+-----+------+\n",
      "|Profit   |1    |100.0 |\n",
      "|Profit   |2    |100.0 |\n",
      "|Profit   |3    |100.0 |\n",
      "|Profit   |4    |100.0 |\n",
      "|Profit   |5    |100.0 |\n",
      "|Profit   |6    |100.0 |\n",
      "|Profit   |7    |100.0 |\n",
      "|Profit   |8    |100.0 |\n",
      "|Profit   |9    |100.0 |\n",
      "|Profit   |10   |100.0 |\n",
      "|Profit   |11   |100.0 |\n",
      "|Profit   |12   |100.0 |\n",
      "|Revenue  |1    |500.0 |\n",
      "|Revenue  |2    |500.0 |\n",
      "|Revenue  |3    |500.0 |\n",
      "|Revenue  |4    |500.0 |\n",
      "|Revenue  |5    |555.0 |\n",
      "|Revenue  |6    |777.0 |\n",
      "|Revenue  |7    |800.0 |\n",
      "|Revenue  |8    |900.0 |\n",
      "+---------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "unPivotDF = df_pivot.unpivot(['Indicator'], ['1','2','3','4','5','6','7','8','9','10','11','12'],\\\n",
    "                             'Month', 'Amount')\n",
    "\n",
    "unPivotDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ce684-f9e3-4b07-88e7-7b3f6d44bdc8",
   "metadata": {},
   "source": [
    "### Agregações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f283b-2885-4036-b112-efd8b938b288",
   "metadata": {},
   "source": [
    "count()\tUse groupBy() count() to return the number of rows for each group. <br>\n",
    "mean()\tReturns the mean of values for each group. <br>\n",
    "max()\tReturns the maximum of values for each group. <br>\n",
    "min()\tReturns the minimum of values for each group. <br>\n",
    "sum()\tReturns the total for values for each group. <br>\n",
    "avg()\tReturns the average for values for each group. <br>\n",
    "agg()\tUsing groupBy() agg() function, we can calculate more than one aggregate at a time. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38477d65-cbd9-4c8d-a7c6-0bfb05008f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unPivotDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69f3b04a-52a9-4f97-83f6-aeeabb34f4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Indicator|avg(Amount)|\n",
      "+---------+-----------+\n",
      "|   Profit|      100.0|\n",
      "|  Revenue|      612.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unPivotDF.groupBy('Indicator').mean('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db9cf962-028d-4883-bfff-ef8b6b315a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Indicator|sum(Amount)|\n",
      "+---------+-----------+\n",
      "|   Profit|     1200.0|\n",
      "|  Revenue|     6732.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unPivotDF.groupBy('Indicator').sum('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f12a84c0-7da3-4f82-8d71-b31fa4b23465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Indicator|max(Amount)|\n",
      "+---------+-----------+\n",
      "|   Profit|      100.0|\n",
      "|  Revenue|     1000.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unPivotDF.groupBy('Indicator').max('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac4dfddf-5445-4d66-85a1-b5a0e6e9bcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Indicator|min(Amount)|\n",
      "+---------+-----------+\n",
      "|   Profit|      100.0|\n",
      "|  Revenue|      300.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unPivotDF.groupBy('Indicator').min('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52916042-9627-4362-9a8a-7cf7446a11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = unPivotDF.groupBy('Indicator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a2c6222-e09c-4c7b-9da5-399cb19764ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types as T, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58b68a95-1592-4099-8f67-77b435b8320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------------------------------------------------------------------+\n",
      "|Indicator|collect_list(Amount)                                                                |\n",
      "+---------+------------------------------------------------------------------------------------+\n",
      "|Profit   |[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]|\n",
      "|Revenue  |[500.0, 500.0, 500.0, 500.0, 555.0, 777.0, 800.0, 900.0, 1000.0, 300.0, 400.0]      |\n",
      "+---------+------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped.agg(F.collect_list(F.col('Amount'))\n",
    "              ).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c226074-2027-4444-9aca-5bd638cc85a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+----------+\n",
      "|job_id|           jod_title|min_salary|max_salary|\n",
      "+------+--------------------+----------+----------+\n",
      "|     1|   Public Accountant|    4200.0|    9000.0|\n",
      "|     2|  Accounting Manager|    8200.0|   16000.0|\n",
      "|     3|Administration As...|    3000.0|    6000.0|\n",
      "|     4|           President|   20000.0|   40000.0|\n",
      "|     5|Administration Vi...|   15000.0|   30000.0|\n",
      "|     6|          Accountant|    4200.0|    9000.0|\n",
      "|     7|     Finance Manager|    8200.0|   16000.0|\n",
      "|     8|Human Resources R...|    4000.0|    9000.0|\n",
      "|     9|          Programmer|    4000.0|   10000.0|\n",
      "|    10|   Marketing Manager|    9000.0|   15000.0|\n",
      "|    11|Marketing Represe...|    4000.0|    9000.0|\n",
      "|    12|Public Relations ...|    4500.0|   10500.0|\n",
      "|    13|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|    14|  Purchasing Manager|    8000.0|   15000.0|\n",
      "|    15|       Sales Manager|   10000.0|   20000.0|\n",
      "|    16|Sales Representative|    6000.0|   12000.0|\n",
      "|    17|      Shipping Clerk|    2500.0|    5500.0|\n",
      "|    18|         Stock Clerk|    2000.0|    5000.0|\n",
      "|    19|       Stock Manager|    5500.0|    8500.0|\n",
      "+------+--------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_jobs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32aad32d-9dab-465b-9d62-2a0e9df6fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_employees.job_id == df_jobs.job_id\n",
    "df_jobs_joined = df_jobs.join(df_employees, condicao , 'inner').select(df_employees['*'],\\\n",
    "                                                                       df_jobs['jod_title'],\\\n",
    "                                                                       df_jobs['min_salary'],\\\n",
    "                                                                       df_jobs['max_salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc0f1f7a-c588-4779-8938-d21c7be9e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------+--------------------+------------+----------+------+-------+----------+-------------+--------------------+----------+----------+\n",
      "|employee_id| first_name| last_name|               email|phone_number| hire_date|job_id| salary|manager_id|department_id|           jod_title|min_salary|max_salary|\n",
      "+-----------+-----------+----------+--------------------+------------+----------+------+-------+----------+-------------+--------------------+----------+----------+\n",
      "|        100|     Steven|      King|steven.king@sqltu...|515.123.4567|1987-06-17|     4|24000.0|      NULL|            9|           President|   20000.0|   40000.0|\n",
      "|        101|      Neena|   Kochhar|neena.kochhar@sql...|515.123.4568|1989-09-21|     5|17000.0|       100|            9|Administration Vi...|   15000.0|   30000.0|\n",
      "|        102|        Lex|   De Haan|lex.de haan@sqltu...|515.123.4569|1993-01-13|     5|17000.0|       100|            9|Administration Vi...|   15000.0|   30000.0|\n",
      "|        103|  Alexander|    Hunold|alexander.hunold@...|590.423.4567|1990-01-03|     9| 9000.0|       102|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        104|      Bruce|     Ernst|bruce.ernst@sqltu...|590.423.4568|1991-05-21|     9| 6000.0|       103|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        105|      David|    Austin|david.austin@sqlt...|590.423.4569|1997-06-25|     9| 4800.0|       103|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        106|      Valli| Pataballa|valli.pataballa@s...|590.423.4560|1998-02-05|     9| 4800.0|       103|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        107|      Diana|   Lorentz|diana.lorentz@sql...|590.423.5567|1999-02-07|     9| 4200.0|       103|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        108|      Nancy| Greenberg|nancy.greenberg@s...|515.124.4569|1994-08-17|     7|12000.0|       101|           10|     Finance Manager|    8200.0|   16000.0|\n",
      "|        109|     Daniel|    Faviet|daniel.faviet@sql...|515.124.4169|1994-08-16|     6| 9000.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        110|       John|      Chen|john.chen@sqltuto...|515.124.4269|1997-09-28|     6| 8200.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        111|     Ismael|   Sciarra|ismael.sciarra@sq...|515.124.4369|1997-09-30|     6| 7700.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        112|Jose Manuel|     Urman|jose manuel.urman...|515.124.4469|1998-03-07|     6| 7800.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        113|       Luis|      Popp|luis.popp@sqltuto...|515.124.4567|1999-12-07|     6| 6900.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        114|        Den|  Raphaely|den.raphaely@sqlt...|515.127.4561|1994-12-07|    14|11000.0|       100|            3|  Purchasing Manager|    8000.0|   15000.0|\n",
      "|        115|  Alexander|      Khoo|alexander.khoo@sq...|515.127.4562|1995-05-18|    13| 3100.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|        116|     Shelli|     Baida|shelli.baida@sqlt...|515.127.4563|1997-12-24|    13| 2900.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|        117|      Sigal|    Tobias|sigal.tobias@sqlt...|515.127.4564|1997-07-24|    13| 2800.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|        118|        Guy|    Himuro|guy.himuro@sqltut...|515.127.4565|1998-11-15|    13| 2600.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|        119|      Karen|Colmenares|karen.colmenares@...|515.127.4566|1999-08-10|    13| 2500.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "+-----------+-----------+----------+--------------------+------------+----------+------+-------+----------+-------------+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_jobs_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e3c945a-b0d0-40df-8801-7e0021b32f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+\n",
      "|Indicator|   sum| mean|\n",
      "+---------+------+-----+\n",
      "|   Profit|1200.0|100.0|\n",
      "|  Revenue|6732.0|612.0|\n",
      "+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,count,mean\n",
    "\n",
    "unPivotDF.groupBy('Indicator').agg(\n",
    "    sum('Amount').alias('sum'),\n",
    "    mean('Amount').alias('mean')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cbaa89-621b-4684-bbb0-15b88b5adfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3eddb7-81d4-44c7-8295-2f0233267d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890538c3-29af-485a-9b45-9e8cf7a0ae79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c6b8c-8f8d-40d7-8376-c994afc31f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb27cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
